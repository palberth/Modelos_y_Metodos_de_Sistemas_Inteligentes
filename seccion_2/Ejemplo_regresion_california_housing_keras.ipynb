{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364c3c53",
   "metadata": {},
   "source": [
    "# Regresión de Precios de Vivienda en California con Redes Neuronales (Keras) y Regularización\n",
    "\n",
    "**Disciplina:** Aprendizaje Profundo, Redes Neuronales, Regresión, Keras (TensorFlow)\n",
    "\n",
    "**Objetivo:**\n",
    "El objetivo de este notebook es construir, entrenar y evaluar una red neuronal para predecir los precios medianos de las viviendas en California utilizando Keras. Se incorporarán técnicas de preprocesamiento, regularización (L2 y Dropout) y callbacks de Keras (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau) para mejorar el entrenamiento y la robustez del modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c354004",
   "metadata": {},
   "source": [
    "## 1. Carga de Librerías y Configuración Inicial\n",
    "\n",
    "**Propósito de esta sección:**\n",
    "Importar todas las bibliotecas necesarias y configurar el entorno para el análisis, incluyendo la fijación de semillas para reproducibilidad.\n",
    "\n",
    "**Bibliotecas Clave:**\n",
    "* **`numpy`, `pandas`**: Para manipulación de datos.\n",
    "* **`matplotlib.pyplot`, `seaborn`**: Para visualizaciones.\n",
    "* **`sklearn.datasets`**: Para cargar el dataset California Housing.\n",
    "* **`sklearn.model_selection`**: Para `train_test_split`.\n",
    "* **`sklearn.preprocessing`**: Para `StandardScaler`.\n",
    "* **`sklearn.metrics`**: Para `mean_squared_error`, `mean_absolute_error`, `r2_score`.\n",
    "* **`tensorflow.keras`**: Para construir y entrenar la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53f7e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comandos mágicos de IPython (opcional en scripts)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11922b9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 18:33:23.328949: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-16 18:33:23.597948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747431203.696393   16278 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747431203.725292   16278 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747431203.953031   16278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747431203.953148   16278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747431203.953152   16278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747431203.953154   16278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-16 18:33:23.976357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importación de bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Configuración para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Configuración de estilo y visualización\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc0eb4",
   "metadata": {},
   "source": [
    "## 2. Funciones Personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312968d6",
   "metadata": {},
   "source": [
    "### Descripción de la Función: `cargar_y_preparar_datos_california`\n",
    "\n",
    "**Objetivo Principal:**\n",
    "Cargar el dataset California Housing, realizar preprocesamiento (escalado de características y, opcionalmente, del objetivo) y dividirlo en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "**Características:**\n",
    "* **Procesamiento:**\n",
    "    1. Carga el dataset California Housing.\n",
    "    2. Crea un DataFrame de Pandas para exploración.\n",
    "    3. Separa características (X) y objetivo (y).\n",
    "    4. Escala las características X (y opcionalmente y) usando `StandardScaler`.\n",
    "    5. Divide los datos en conjuntos de entrenamiento y prueba.\n",
    "* **Valor de Retorno:**\n",
    "    * `X_train, X_test, y_train, y_test`: Conjuntos de datos divididos y preprocesados.\n",
    "    * `scaler_X`, `scaler_y` (opcional): Los objetos `StandardScaler` ajustados.\n",
    "    * `feature_names`: Nombres de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d70b000",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def cargar_y_preparar_datos_california(test_size=0.2, random_state=SEED, scale_target=False):\n",
    "    \"\"\"\n",
    "    Carga, preprocesa y divide el dataset California Housing.\n",
    "    \"\"\"\n",
    "    print(\"Cargando y preparando el dataset California Housing...\")\n",
    "    housing = fetch_california_housing()\n",
    "    X = housing.data\n",
    "    y = housing.target\n",
    "    feature_names = housing.feature_names\n",
    "\n",
    "    df = pd.DataFrame(X, columns=feature_names)\n",
    "    df['MedHouseVal'] = y\n",
    "    print(\"\\nPrimeras filas del dataset California Housing:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nDescripción del dataset:\")\n",
    "    print(df.describe().T)\n",
    "\n",
    "    # Escalar características\n",
    "    scaler_X = StandardScaler()\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    \n",
    "    y_scaled = y # Por defecto, no escalar y\n",
    "    scaler_y = None\n",
    "    if scale_target:\n",
    "        scaler_y = StandardScaler()\n",
    "        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten() # Reshape para scaler y luego flatten\n",
    "\n",
    "    # Dividir datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_scaled, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nDimensiones: X_train: {X_train.shape}, y_train: {y_train.shape}, X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test, scaler_X, scaler_y, feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f131a7",
   "metadata": {},
   "source": [
    "### Descripción de la Función: `crear_modelo_regresion_keras`\n",
    "\n",
    "**Objetivo Principal:**\n",
    "Definir y compilar un modelo de red neuronal secuencial con Keras para regresión.\n",
    "\n",
    "**Características:**\n",
    "* **Entrada:**\n",
    "    * `input_dim` (int): Número de características de entrada.\n",
    "* **Procesamiento:**\n",
    "    1. Crea un modelo `Sequential`.\n",
    "    2. Añade capas `Dense` con activación 'relu', regularización L2 y Dropout.\n",
    "       (Considerar `BatchNormalization` opcionalmente).\n",
    "    3. Añade una capa de salida `Dense` con 1 neurona (sin activación o 'linear') para regresión.\n",
    "    4. Compila el modelo con optimizador 'adam', pérdida 'mean_squared_error' (MSE) y métricas 'mean_absolute_error' (MAE).\n",
    "* **Valor de Retorno:**\n",
    "    * `model` (tf.keras.Model): El modelo Keras compilado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1e59c8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def crear_modelo_regresion_keras(input_dim, l2_lambda=0.001, dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    Crea un modelo de red neuronal para regresión con Keras.\n",
    "    \"\"\"\n",
    "    print(\"\\nCreando el modelo de regresión con Keras...\")\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,), kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "        # BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "        # BatchNormalization(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)),\n",
    "        Dense(1) # Capa de salida para regresión (predice un solo valor continuo)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mean_squared_error', # MSE es común para regresión\n",
    "                  metrics=['mean_absolute_error']) # MAE es otra métrica útil\n",
    "    \n",
    "    print(\"\\nResumen del modelo:\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa9cd7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `graficar_historial_entrenamiento_regresion`\n",
    "(Similar a la de clasificación, pero para métricas de regresión)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b13240",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def graficar_historial_entrenamiento_regresion(history):\n",
    "    \"\"\"\n",
    "    Grafica la pérdida (MSE) y MAE durante el entrenamiento y validación.\n",
    "    \"\"\"\n",
    "    print(\"\\nGraficando historial de entrenamiento (Regresión)...\")\n",
    "    loss = history.history.get('loss')\n",
    "    val_loss = history.history.get('val_loss')\n",
    "    mae = history.history.get('mean_absolute_error')\n",
    "    val_mae = history.history.get('val_mean_absolute_error')\n",
    "    epochs_range = range(len(loss if loss else mae))\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if loss and val_loss:\n",
    "        plt.plot(epochs_range, loss, label='Pérdida (MSE) - Entrenamiento')\n",
    "        plt.plot(epochs_range, val_loss, label='Pérdida (MSE) - Validación')\n",
    "        plt.title('Pérdida (MSE) de Entrenamiento y Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('MSE')\n",
    "        plt.legend(loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if mae and val_mae:\n",
    "        plt.plot(epochs_range, mae, label='MAE - Entrenamiento')\n",
    "        plt.plot(epochs_range, val_mae, label='MAE - Validación')\n",
    "        plt.title('Error Absoluto Medio (MAE) de Entrenamiento y Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('MAE')\n",
    "        plt.legend(loc='upper right')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91438b9",
   "metadata": {},
   "source": [
    "### Descripción de la Función: `evaluar_y_visualizar_regresion`\n",
    "\n",
    "**Objetivo Principal:**\n",
    "Evaluar el modelo de regresión y visualizar sus predicciones.\n",
    "\n",
    "**Características:**\n",
    "* **Entrada:**\n",
    "    * `model` (tf.keras.Model): Modelo Keras entrenado.\n",
    "    * `X_test`, `y_test`: Datos de prueba.\n",
    "    * `scaler_y` (StandardScaler, opcional): Scaler usado para el objetivo (si se escaló).\n",
    "* **Procesamiento:**\n",
    "    1. Evalúa el modelo (MSE, MAE).\n",
    "    2. Realiza predicciones.\n",
    "    3. Si `scaler_y` fue provisto, desescala `y_test` e `y_pred` para interpretación.\n",
    "    4. Calcula R² score.\n",
    "    5. Grafica Predicciones vs. Reales y Residuales.\n",
    "* **Salida:** Muestra métricas y gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd2eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_y_visualizar_regresion(model, X_test, y_test_orig, scaler_y=None):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo de regresión y visualiza predicciones y residuales.\n",
    "    y_test_orig son los valores verdaderos (potencialmente escalados si scaler_y no es None).\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluando el modelo de regresión en el conjunto de prueba...\")\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test_orig, verbose=0)\n",
    "    print(f\"Pérdida (MSE) en el conjunto de prueba: {test_loss:.4f}\")\n",
    "    print(f\"Error Absoluto Medio (MAE) en el conjunto de prueba: {test_mae:.4f}\")\n",
    "\n",
    "    y_pred_scaled = model.predict(X_test).flatten()\n",
    "    \n",
    "    y_test_final = y_test_orig\n",
    "    y_pred_final = y_pred_scaled\n",
    "\n",
    "    if scaler_y:\n",
    "        print(\"Desescalando predicciones y valores reales para métricas e interpretación...\")\n",
    "        y_test_final = scaler_y.inverse_transform(y_test_orig.reshape(-1,1)).flatten()\n",
    "        y_pred_final = scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1)).flatten()\n",
    "        \n",
    "        # Recalcular MAE con valores desescalados para interpretabilidad\n",
    "        mae_descalado = mean_absolute_error(y_test_final, y_pred_final)\n",
    "        print(f\"MAE (desescalado) en el conjunto de prueba: {mae_descalado:.4f} (en unidades originales del precio)\")\n",
    "\n",
    "    r2 = r2_score(y_test_final, y_pred_final)\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "    # Gráfico de Predicciones vs. Reales\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test_final, y_pred_final, alpha=0.5)\n",
    "    plt.plot([min(y_test_final), max(y_test_final)], [min(y_test_final), max(y_test_final)], '--', color='red', lw=2)\n",
    "    plt.xlabel('Valores Reales')\n",
    "    plt.ylabel('Predicciones')\n",
    "    plt.title('Predicciones vs. Valores Reales')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Gráfico de Residuales\n",
    "    residuals = y_test_final - y_pred_final\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.xlabel('Residuales (Real - Predicción)')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.title('Distribución de los Residuales')\n",
    "    plt.axvline(0, color='red', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_pred_final, residuals, alpha=0.5)\n",
    "    plt.xlabel('Valores Predichos')\n",
    "    plt.ylabel('Residuales')\n",
    "    plt.title('Residuales vs. Valores Predichos')\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53608bae",
   "metadata": {},
   "source": [
    "## 3. Desarrollo del Ejercicio: Regresión de Precios de Vivienda con Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24866d07",
   "metadata": {},
   "source": [
    "### 3.1. Carga y Preparación de Datos\n",
    "\n",
    "Cargamos el dataset California Housing, lo escalamos y dividimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7c8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y preparando el dataset California Housing...\n",
      "\n",
      "Primeras filas del dataset California Housing:\n",
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  MedHouseVal  \n",
      "0    -122.23        4.526  \n",
      "1    -122.22        3.585  \n",
      "2    -122.24        3.521  \n",
      "3    -122.25        3.413  \n",
      "4    -122.25        3.422  \n",
      "\n",
      "Descripción del dataset:\n",
      "               count         mean          std         min         25%  \\\n",
      "MedInc       20640.0     3.870671     1.899822    0.499900    2.563400   \n",
      "HouseAge     20640.0    28.639486    12.585558    1.000000   18.000000   \n",
      "AveRooms     20640.0     5.429000     2.474173    0.846154    4.440716   \n",
      "AveBedrms    20640.0     1.096675     0.473911    0.333333    1.006079   \n",
      "Population   20640.0  1425.476744  1132.462122    3.000000  787.000000   \n",
      "AveOccup     20640.0     3.070655    10.386050    0.692308    2.429741   \n",
      "Latitude     20640.0    35.631861     2.135952   32.540000   33.930000   \n",
      "Longitude    20640.0  -119.569704     2.003532 -124.350000 -121.800000   \n",
      "MedHouseVal  20640.0     2.068558     1.153956    0.149990    1.196000   \n",
      "\n",
      "                     50%          75%           max  \n",
      "MedInc          3.534800     4.743250     15.000100  \n",
      "HouseAge       29.000000    37.000000     52.000000  \n",
      "AveRooms        5.229129     6.052381    141.909091  \n",
      "AveBedrms       1.048780     1.099526     34.066667  \n",
      "Population   1166.000000  1725.000000  35682.000000  \n",
      "AveOccup        2.818116     3.282261   1243.333333  \n",
      "Latitude       34.260000    37.710000     41.950000  \n",
      "Longitude    -118.490000  -118.010000   -114.310000  \n",
      "MedHouseVal     1.797000     2.647250      5.000010  \n",
      "\n",
      "Dimensiones: X_train: (16512, 8), y_train: (16512,), X_test: (4128, 8), y_test: (4128,)\n"
     ]
    }
   ],
   "source": [
    "# scale_target=True puede ayudar si la distribución de y es muy amplia o sesgada.\n",
    "# Para este ejemplo, empecemos con scale_target=False para simplificar la interpretación inicial del MAE.\n",
    "# Si el rendimiento no es bueno, se puede probar escalar el objetivo.\n",
    "X_train_housing, X_test_housing, y_train_housing, y_test_housing, scaler_X_housing, scaler_y_housing, housing_feature_names = \\\n",
    "    cargar_y_preparar_datos_california(scale_target=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0addcc",
   "metadata": {},
   "source": [
    "### 3.2. Creación del Modelo de Regresión\n",
    "\n",
    "Definimos la arquitectura de nuestra red neuronal para la tarea de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e56e988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creando el modelo de regresión con Keras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1747431211.887400   16278 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3539 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen del modelo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,521</span> (45.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,521\u001b[0m (45.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,521</span> (45.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,521\u001b[0m (45.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim_housing = X_train_housing.shape[1]\n",
    "\n",
    "modelo_housing = crear_modelo_regresion_keras(input_dim_housing, l2_lambda=0.01, dropout_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e81548f",
   "metadata": {},
   "source": [
    "### 3.3. Entrenamiento del Modelo\n",
    "\n",
    "Entrenamos el modelo de regresión, utilizando callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "482f853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando el entrenamiento del modelo de regresión California Housing...\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747431213.653128   16388 service.cc:152] XLA service 0x7f308400b680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747431213.653172   16388 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9\n",
      "2025-05-16 18:33:33.693152: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "E0000 00:00:1747431213.865714   16388 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "E0000 00:00:1747431213.939073   16388 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-05-16 18:33:33.944783: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at xla_ops.cc:591 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2025-05-16 18:33:33.944861: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_16278/1762030180.py\", line 11, in <module>\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_1987]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m callbacks_list_reg \u001b[38;5;241m=\u001b[39m [early_stopping_reg, model_checkpoint_reg, reduce_lr_reg]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m history_housing \u001b[38;5;241m=\u001b[39m modelo_housing\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     12\u001b[0m     X_train_housing, y_train_housing,\n\u001b[1;32m     13\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, \u001b[38;5;66;03m# Un número alto de épocas\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     15\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;66;03m# Usar una porción de los datos de entrenamiento para validación interna\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks_list_reg,\n\u001b[1;32m     17\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/MADSI/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_16278/1762030180.py\", line 11, in <module>\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/santiago/anaconda3/envs/MADSI/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_1987]"
     ]
    }
   ],
   "source": [
    "print(\"\\nIniciando el entrenamiento del modelo de regresión California Housing...\")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_reg = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1) # Más paciencia para regresión\n",
    "model_checkpoint_reg = ModelCheckpoint('best_housing_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "reduce_lr_reg = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "callbacks_list_reg = [early_stopping_reg, model_checkpoint_reg, reduce_lr_reg]\n",
    "\n",
    "# Entrenamiento\n",
    "history_housing = modelo_housing.fit(\n",
    "    X_train_housing, y_train_housing,\n",
    "    epochs=250, # Un número alto de épocas\n",
    "    batch_size=32,\n",
    "    validation_split=0.2, # Usar una porción de los datos de entrenamiento para validación interna\n",
    "    callbacks=callbacks_list_reg,\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "# modelo_housing = keras.models.load_model('best_housing_model.keras') # Si EarlyStopping no tiene restore_best_weights=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d94dfd",
   "metadata": {},
   "source": [
    "### 3.4. Visualización del Historial de Entrenamiento\n",
    "\n",
    "Observamos cómo evolucionaron la pérdida (MSE) y el MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history_housing:\n",
    "    graficar_historial_entrenamiento_regresion(history_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44589dc6",
   "metadata": {},
   "source": [
    "### 3.5. Evaluación del Modelo\n",
    "\n",
    "Evaluamos el rendimiento del modelo de regresión en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelo_housing:\n",
    "    evaluar_y_visualizar_regresion(modelo_housing, X_test_housing, y_test_housing, scaler_y_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0384d",
   "metadata": {},
   "source": [
    "## 4. Conclusiones del Ejercicio (Regresión California Housing)\n",
    "\n",
    "**Resumen de Hallazgos:**\n",
    "* Se cargó y preprocesó el dataset California Housing, escalando las características de entrada.\n",
    "* Se construyó una red neuronal secuencial con Keras para regresión, incluyendo:\n",
    "    * Capas `Dense` con activación ReLU.\n",
    "    * Regularización L2 (`kernel_regularizer`) y capas `Dropout` para mitigar el sobreajuste.\n",
    "    * Una capa de salida `Dense` lineal con una sola neurona para predecir el valor continuo.\n",
    "* El modelo fue compilado con el optimizador `adam`, función de pérdida `mean_squared_error` (MSE) y la métrica `mean_absolute_error` (MAE).\n",
    "* Se utilizaron callbacks (`EarlyStopping`, `ModelCheckpoint`, `ReduceLROnPlateau`) durante el entrenamiento para mejorar la eficiencia y el rendimiento.\n",
    "* El modelo alcanzó un Error Absoluto Medio (MAE) en el conjunto de prueba de **[Completar con MAE obtenido, ej: $0.35, lo que significaría un error promedio de $35,000 si el target está en cientos de miles]** y un R² de **[Completar con R² obtenido, ej: 0.80]**.\n",
    "* Las curvas de aprendizaje (MSE y MAE vs. épocas) y los gráficos de predicciones vs. reales y de residuales ayudaron a evaluar el ajuste y el comportamiento del modelo.\n",
    "\n",
    "**Aprendizaje General:**\n",
    "Este ejercicio ilustró la aplicación de redes neuronales profundas con Keras para un problema de regresión. Se demostró la importancia del preprocesamiento de datos, la inclusión de técnicas de regularización para construir modelos más generalizables, y el uso de callbacks para un entrenamiento robusto. La evaluación mediante múltiples métricas y visualizaciones es crucial para entender el rendimiento de un modelo de regresión.\n",
    "\n",
    "*(Nota: Los resultados específicos deben completarse después de ejecutar completamente el notebook.)*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "MADSI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
