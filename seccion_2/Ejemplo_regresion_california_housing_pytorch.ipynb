{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac5687e",
   "metadata": {},
   "source": [
    "# Regresión de Precios de Vivienda en California con Redes Neuronales (PyTorch) y Regularización\n",
    "\n",
    "**Disciplina:** Aprendizaje Profundo, Redes Neuronales, Regresión, PyTorch\n",
    "\n",
    "**Objetivo:**\n",
    "El objetivo de este notebook es construir, entrenar y evaluar una red neuronal para predecir los precios medianos de las viviendas en California utilizando PyTorch. Se incorporarán técnicas de preprocesamiento, regularización (Weight Decay y Dropout) y manejo explícito del bucle de entrenamiento con funcionalidades equivalentes a callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau) para mejorar el entrenamiento y la robustez del modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bacb3c",
   "metadata": {},
   "source": [
    "## 1. Carga de Librerías y Configuración Inicial\n",
    "\n",
    "**Propósito de esta sección:**\n",
    "Importar todas las bibliotecas necesarias y configurar el entorno para el análisis.\n",
    "\n",
    "**Bibliotecas Clave:**\n",
    "* **`numpy`, `pandas`**: Para manipulación de datos.\n",
    "* **`matplotlib.pyplot`, `seaborn`**: Para visualizaciones.\n",
    "* **`sklearn.datasets`**: Para cargar el dataset California Housing.\n",
    "* **`sklearn.model_selection`**: Para `train_test_split`.\n",
    "* **`sklearn.preprocessing`**: Para `StandardScaler`.\n",
    "* **`sklearn.metrics`**: Para `mean_squared_error`, `mean_absolute_error`, `r2_score`.\n",
    "* **`torch`, `torch.nn`, `torch.optim`, `torch.utils.data`**: Para PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comandos mágicos de IPython (opcional en scripts)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6c4628",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importación de bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Importar PyTorch\n",
    "PYTORCH_IMPORTED_SUCCESSFULLY = False # <--- DEFINIR LA BANDERA AQUÍ\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    print(f\"Biblioteca 'torch' importada correctamente. Versión: {torch.__version__}\")\n",
    "    PYTORCH_IMPORTED_SUCCESSFULLY = True # <--- ACTUALIZAR LA BANDERA\n",
    "except ImportError as e:\n",
    "    print(f\"Error al importar 'torch': {e}\")\n",
    "    print(\"Por favor, instálala con 'pip install torch torchvision torchaudio' (o según tu sistema).\")\n",
    "    print(\"El script continuará, pero las secciones de PyTorch probablemente fallarán.\")\n",
    "\n",
    "\n",
    "# Configuración para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY:\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Configuración de dispositivo\n",
    "device = torch.device(\"cuda\" if PYTORCH_IMPORTED_SUCCESSFULLY and torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Configuración de estilo y visualización\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc71ab",
   "metadata": {},
   "source": [
    "## 2. Funciones Personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad59db9",
   "metadata": {},
   "source": [
    "### Descripción de la Función: `cargar_y_preparar_datos_california_pytorch`\n",
    "\n",
    "**Objetivo Principal:**\n",
    "Cargar el dataset California Housing, preprocesarlo (escalado), convertir a tensores PyTorch y crear DataLoaders.\n",
    "\n",
    "**Características:**\n",
    "* **Procesamiento:**\n",
    "    1. Carga el dataset.\n",
    "    2. Escala características X (y opcionalmente y) con `StandardScaler`.\n",
    "    3. Convierte a tensores PyTorch (y debe ser `(N,1)` para regresión con `MSELoss`).\n",
    "    4. Divide en entrenamiento, validación y prueba.\n",
    "    5. Crea `DataLoader` para cada conjunto.\n",
    "* **Valor de Retorno:** DataLoaders, scalers, nombres, datos NumPy de entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b60a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_preparar_datos_california_pytorch(batch_size=32, test_size=0.2, val_size=0.1, random_state=SEED, scale_target=False):\n",
    "    print(\"Cargando y preparando el dataset California Housing para PyTorch...\")\n",
    "    housing = fetch_california_housing()\n",
    "    X_np = housing.data\n",
    "    y_np = housing.target\n",
    "    feature_names = housing.feature_names\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    X_scaled_np = scaler_X.fit_transform(X_np)\n",
    "    \n",
    "    y_processed_np = y_np # y original para las métricas finales si no se escala y\n",
    "    scaler_y = None\n",
    "    if scale_target:\n",
    "        scaler_y = StandardScaler()\n",
    "        # y_processed_np es la versión que irá a los tensores y al entrenamiento\n",
    "        y_processed_np = scaler_y.fit_transform(y_np.reshape(-1, 1)).flatten()\n",
    "\n",
    "    X_temp_np, X_test_np, y_temp_np, y_test_np = train_test_split(\n",
    "        X_scaled_np, y_processed_np, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    val_proportion_of_temp = val_size / (1 - test_size) if (1-test_size) > 0 else 0\n",
    "    if val_proportion_of_temp == 0 and len(X_temp_np) > 0:\n",
    "        X_train_np, X_val_np, y_train_np, y_val_np = X_temp_np, np.array([]), y_temp_np, np.array([])\n",
    "        X_val_np = np.empty((0, X_train_np.shape[1]), dtype=X_train_np.dtype)\n",
    "        y_val_np = np.empty((0,), dtype=y_train_np.dtype)\n",
    "    elif val_proportion_of_temp > 0:\n",
    "         X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "            X_temp_np, y_temp_np, test_size=val_proportion_of_temp, random_state=random_state\n",
    "        )\n",
    "    else: # X_temp_np is empty\n",
    "        X_train_np, X_val_np, y_train_np, y_val_np = X_temp_np, X_temp_np, y_temp_np, y_temp_np\n",
    "\n",
    "\n",
    "    train_loader, val_loader, test_loader = None, None, None\n",
    "    if PYTORCH_IMPORTED_SUCCESSFULLY:\n",
    "        X_train_torch = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "        y_train_torch = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1)\n",
    "        X_val_torch = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "        y_val_torch = torch.tensor(y_val_np, dtype=torch.float32).unsqueeze(1)\n",
    "        X_test_torch = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "        y_test_torch = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        if X_val_torch.shape[0] > 0:\n",
    "            val_dataset = TensorDataset(X_val_torch, y_val_torch)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"\\nDimensiones NumPy: X_train: {X_train_np.shape}, y_train: {y_train_np.shape}\")\n",
    "    print(f\"Dimensiones NumPy: X_val: {X_val_np.shape}, y_val: {y_val_np.shape}\")\n",
    "    print(f\"Dimensiones NumPy: X_test: {X_test_np.shape}, y_test: {y_test_np.shape}\")\n",
    "    if train_loader:\n",
    "        print(f\"Tamaños DataLoaders: Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset) if val_loader else 0}, Test: {len(test_loader.dataset)}\")\n",
    "    \n",
    "    # Devolver y_test_np (que está escalado o no según scale_target) para la evaluación final\n",
    "    # y y_np (el original, sin escalar) para referencia si es necesario.\n",
    "    return (train_loader, val_loader, test_loader, \n",
    "            scaler_X, scaler_y, feature_names, \n",
    "            X_train_np, X_val_np, X_test_np,\n",
    "            y_train_np, y_val_np, y_test_np, y_np) # Añadir y_np original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99b18a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Clase: `HousingRegressorNet`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba0e37d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if PYTORCH_IMPORTED_SUCCESSFULLY:\n",
    "    class HousingRegressorNet(nn.Module):\n",
    "        def __init__(self, input_dim, dropout_rate=0.3):\n",
    "            super(HousingRegressorNet, self).__init__()\n",
    "            # Aumentar un poco la complejidad para California Housing\n",
    "            self.fc1 = nn.Linear(input_dim, 128) \n",
    "            self.relu1 = nn.ReLU()\n",
    "            # self.bn1 = nn.BatchNorm1d(128) # Opcional Batch Norm\n",
    "            self.dropout1 = nn.Dropout(dropout_rate)\n",
    "            \n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            # self.bn2 = nn.BatchNorm1d(64)\n",
    "            self.dropout2 = nn.Dropout(dropout_rate)\n",
    "            \n",
    "            self.fc3 = nn.Linear(64, 32)\n",
    "            self.relu3 = nn.ReLU()\n",
    "            \n",
    "            self.fc4 = nn.Linear(32, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu1(x)\n",
    "            # x = self.bn1(x)\n",
    "            x = self.dropout1(x)\n",
    "            \n",
    "            x = self.fc2(x)\n",
    "            x = self.relu2(x)\n",
    "            # x = self.bn2(x)\n",
    "            x = self.dropout2(x)\n",
    "            \n",
    "            x = self.fc3(x)\n",
    "            x = self.relu3(x)\n",
    "            \n",
    "            x = self.fc4(x)\n",
    "            return x\n",
    "else:\n",
    "    HousingRegressorNet = None\n",
    "    print(\"PyTorch no importado, HousingRegressorNet no definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c56790",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `entrenar_modelo_regresion_pytorch`\n",
    "(Sin cambios, pero su ejecución dependerá de PYTORCH_IMPORTED_SUCCESSFULLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89caccf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def entrenar_modelo_regresion_pytorch(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                                      num_epochs, patience, model_save_path, device):\n",
    "    if not PYTORCH_IMPORTED_SUCCESSFULLY or model is None:\n",
    "        print(\"PyTorch no disponible o modelo no definido. Saltando entrenamiento de regresión.\")\n",
    "        return {\"train_loss\": [], \"val_loss\": [], \"train_mae\": [], \"val_mae\": []}\n",
    "\n",
    "    print(f\"\\nIniciando entrenamiento de regresión en {device} por {num_epochs} épocas...\")\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_maes, val_maes = [], [] \n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        running_mae_train = 0.0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss_train += loss.item() * inputs.size(0)\n",
    "            running_mae_train += torch.abs(outputs - targets).sum().item()\n",
    "            \n",
    "        epoch_loss_train = running_loss_train / len(train_loader.dataset) if len(train_loader.dataset) > 0 else 0\n",
    "        epoch_mae_train = running_mae_train / len(train_loader.dataset) if len(train_loader.dataset) > 0 else 0\n",
    "        train_losses.append(epoch_loss_train)\n",
    "        train_maes.append(epoch_mae_train)\n",
    "\n",
    "        epoch_loss_val = float('nan')\n",
    "        epoch_mae_val = float('nan')\n",
    "\n",
    "        if val_loader and len(val_loader.dataset) > 0:\n",
    "            model.eval()\n",
    "            running_loss_val = 0.0\n",
    "            running_mae_val = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_loader:\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss_val_batch = criterion(outputs, targets)\n",
    "                    running_loss_val += loss_val_batch.item() * inputs.size(0)\n",
    "                    running_mae_val += torch.abs(outputs - targets).sum().item()\n",
    "            \n",
    "            epoch_loss_val = running_loss_val / len(val_loader.dataset) if len(val_loader.dataset) > 0 else 0\n",
    "            epoch_mae_val = running_mae_val / len(val_loader.dataset) if len(val_loader.dataset) > 0 else 0\n",
    "        \n",
    "        val_losses.append(epoch_loss_val)\n",
    "        val_maes.append(epoch_mae_val)\n",
    "        \n",
    "        print(f\"Época {epoch+1}/{num_epochs} | \"\n",
    "              f\"Pérdida Ent. (MSE): {epoch_loss_train:.4f} | MAE Ent.: {epoch_mae_train:.4f} | \"\n",
    "              f\"Pérdida Val. (MSE): {epoch_loss_val:.4f} | MAE Val.: {epoch_mae_val:.4f}\")\n",
    "\n",
    "        if scheduler and not np.isnan(epoch_loss_val):\n",
    "            scheduler.step(epoch_loss_val)\n",
    "\n",
    "        if not np.isnan(epoch_loss_val) and epoch_loss_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_val\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_state, model_save_path)\n",
    "            print(f\"  Mejora en validación (Pérdida Val.: {best_val_loss:.4f}). Guardando modelo en {model_save_path}\")\n",
    "            epochs_no_improve = 0\n",
    "        elif not np.isnan(epoch_loss_val) :\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Sin mejora en validación por {epochs_no_improve} épocas.\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping activado. Mejor val_loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "        elif np.isnan(epoch_loss_val) and epoch == 0:\n",
    "             best_model_state = copy.deepcopy(model.state_dict())\n",
    "             torch.save(best_model_state, model_save_path)\n",
    "             print(f\"  No hay set de validación. Guardando modelo de época 1 en {model_save_path}\")\n",
    "                \n",
    "    if best_model_state:\n",
    "        print(f\"Cargando los pesos del mejor modelo desde {model_save_path} (mejor val_loss: {best_val_loss:.4f})\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    return {\"train_loss\": train_losses, \"val_loss\": val_losses, \n",
    "            \"train_mae\": train_maes, \"val_mae\": val_maes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebf4662",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `graficar_historial_regresion_pytorch`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a6e55",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def graficar_historial_regresion_pytorch(history_dict):\n",
    "    print(\"\\nGraficando historial de entrenamiento (Regresión PyTorch)...\")\n",
    "    train_loss = history_dict.get('train_loss')\n",
    "    val_loss = history_dict.get('val_loss')\n",
    "    train_mae = history_dict.get('train_mae')\n",
    "    val_mae = history_dict.get('val_mae')\n",
    "\n",
    "    val_loss_plot = [v for v in val_loss if not np.isnan(v)] if val_loss else []\n",
    "    val_mae_plot = [v for v in val_mae if not np.isnan(v)] if val_mae else []\n",
    "    \n",
    "    epochs_range_train = range(len(train_loss if train_loss else train_mae))\n",
    "    epochs_range_val = range(len(val_loss_plot if val_loss_plot else val_mae_plot))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if train_loss:\n",
    "        plt.plot(epochs_range_train, train_loss, label='Pérdida (MSE) - Entrenamiento')\n",
    "        if val_loss_plot:\n",
    "            plt.plot(epochs_range_val, val_loss_plot, label='Pérdida (MSE) - Validación')\n",
    "        plt.title('Pérdida (MSE) de Entrenamiento y Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('MSE'); plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if train_mae:\n",
    "        plt.plot(epochs_range_train, train_mae, label='MAE - Entrenamiento')\n",
    "        if val_mae_plot:\n",
    "            plt.plot(epochs_range_val, val_mae_plot, label='MAE - Validación')\n",
    "        plt.title('Error Absoluto Medio (MAE)'); plt.xlabel('Épocas'); plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473497a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `evaluar_modelo_regresion_pytorch`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8815b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo_regresion_pytorch(model, test_loader, criterion, \n",
    "                                     X_test_numpy_for_eval, y_test_numpy_for_eval, \n",
    "                                     scaler_y=None, device=device):\n",
    "    if not PYTORCH_IMPORTED_SUCCESSFULLY or model is None:\n",
    "        print(\"PyTorch no disponible o modelo no definido. Saltando evaluación de regresión.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nEvaluando el modelo de regresión PyTorch en el conjunto de prueba...\")\n",
    "    model.eval()\n",
    "    test_loss_mse_sum = 0.0\n",
    "    test_mae_sum = 0.0 # MAE calculado sobre los datos (posiblemente escalados) del test_loader\n",
    "    all_preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader: \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets) \n",
    "            test_loss_mse_sum += loss.item() * inputs.size(0)\n",
    "            test_mae_sum += torch.abs(outputs - targets).sum().item()\n",
    "            all_preds_list.append(outputs.cpu().numpy()) \n",
    "            \n",
    "    avg_test_loss_mse = test_loss_mse_sum / len(y_test_numpy_for_eval) if len(y_test_numpy_for_eval) > 0 else 0\n",
    "    avg_test_mae_pytorch = test_mae_sum / len(y_test_numpy_for_eval) if len(y_test_numpy_for_eval) > 0 else 0\n",
    "    \n",
    "    print(f\"Pérdida Promedio (MSE) en el conjunto de prueba: {avg_test_loss_mse:.4f}\")\n",
    "    print(f\"MAE Promedio (calculado por PyTorch sobre datos de test_loader): {avg_test_mae_pytorch:.4f}\")\n",
    "\n",
    "    y_pred_from_loader = np.concatenate(all_preds_list).flatten()\n",
    "    \n",
    "    # y_test_numpy_for_eval es el y_test que corresponde a X_test_numpy_for_eval\n",
    "    # y_pred_from_loader son las predicciones para X_test_numpy_for_eval\n",
    "    # Ambos están en la misma escala (la que se usó para el entrenamiento/test_loader)\n",
    "    \n",
    "    y_test_final_for_metrics = y_test_numpy_for_eval \n",
    "    y_pred_final_for_metrics = y_pred_from_loader\n",
    "\n",
    "    y_test_to_plot = y_test_numpy_for_eval\n",
    "    y_pred_to_plot = y_pred_from_loader\n",
    "    \n",
    "    if scaler_y: # Si el target original (y_test_numpy_for_eval) fue escalado\n",
    "        print(\"Desescalando predicciones y valores reales para R2 e interpretación...\")\n",
    "        y_test_to_plot = scaler_y.inverse_transform(y_test_numpy_for_eval.reshape(-1,1)).flatten()\n",
    "        y_pred_to_plot = scaler_y.inverse_transform(y_pred_from_loader.reshape(-1,1)).flatten()\n",
    "        \n",
    "        mae_descalado = mean_absolute_error(y_test_to_plot, y_pred_to_plot)\n",
    "        print(f\"MAE (desescalado, unidades originales) en el conjunto de prueba: {mae_descalado:.4f}\")\n",
    "\n",
    "    r2 = r2_score(y_test_to_plot, y_pred_to_plot)\n",
    "    print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_test_to_plot, y_pred_to_plot, alpha=0.5)\n",
    "    min_val_plot = min(np.min(y_test_to_plot), np.min(y_pred_to_plot))\n",
    "    max_val_plot = max(np.max(y_test_to_plot), np.max(y_pred_to_plot))\n",
    "    plt.plot([min_val_plot, max_val_plot], [min_val_plot, max_val_plot], '--', color='red', lw=2)\n",
    "    plt.xlabel('Valores Reales (Unidad Original si desescalado)')\n",
    "    plt.ylabel('Predicciones (Unidad Original si desescalado)')\n",
    "    plt.title('Predicciones vs. Valores Reales (PyTorch)')\n",
    "    plt.grid(True); plt.show()\n",
    "\n",
    "    residuals = y_test_to_plot - y_pred_to_plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(residuals, kde=True)\n",
    "    plt.xlabel('Residuales (Real - Predicción)'); plt.ylabel('Frecuencia')\n",
    "    plt.title('Distribución de los Residuales (PyTorch)'); plt.axvline(0, color='red', linestyle='--')\n",
    "    plt.grid(True); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_pred_to_plot, residuals, alpha=0.5)\n",
    "    plt.xlabel('Valores Predichos'); plt.ylabel('Residuales')\n",
    "    plt.title('Residuales vs. Valores Predichos (PyTorch)'); plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23050f9a",
   "metadata": {},
   "source": [
    "## 3. Desarrollo del Ejercicio: Regresión de Precios de Vivienda con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3835ca",
   "metadata": {},
   "source": [
    "### 3.1. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de330ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_HOUSING = 64\n",
    "(train_loader_housing, val_loader_housing, test_loader_housing, \n",
    " scaler_X_housing, scaler_y_housing, housing_feature_names,\n",
    " X_train_housing_np, X_val_housing_np, X_test_housing_np,\n",
    " y_train_housing_np, y_val_housing_np, y_test_housing_np,\n",
    " y_housing_original_np # y original sin escalar\n",
    " ) = cargar_y_preparar_datos_california_pytorch(\n",
    "        batch_size=BATCH_SIZE_HOUSING, \n",
    "        scale_target=True # Probar escalar el target para regresión\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8fbf1",
   "metadata": {},
   "source": [
    "### 3.2. Creación del Modelo de Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e1d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_housing_pytorch = None\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY and HousingRegressorNet is not None:\n",
    "    if X_train_housing_np.shape[0] > 0:\n",
    "        input_dim_housing_actual = X_train_housing_np.shape[1]\n",
    "    elif train_loader_housing and len(train_loader_housing.dataset) > 0:\n",
    "        sample_inputs_housing, _ = next(iter(train_loader_housing))\n",
    "        input_dim_housing_actual = sample_inputs_housing.shape[1]\n",
    "    else:\n",
    "        print(\"No se pudo determinar input_dim para el modelo Housing. Usando valor por defecto 8.\")\n",
    "        input_dim_housing_actual = 8 # California Housing tiene 8 características\n",
    "\n",
    "    modelo_housing_pytorch = HousingRegressorNet(input_dim_housing_actual, dropout_rate=0.2).to(device)\n",
    "    print(\"\\nResumen del modelo PyTorch de Regresión (estructura):\")\n",
    "    print(modelo_housing_pytorch)\n",
    "else:\n",
    "    print(\"PyTorch no se importó o HousingRegressorNet no definido, saltando creación de modelo de regresión.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff47377",
   "metadata": {},
   "source": [
    "### 3.3. Definición de Pérdida, Optimizador y Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c86c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_housing, optimizer_housing, scheduler_housing = None, None, None\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY and modelo_housing_pytorch:\n",
    "    criterion_housing = nn.MSELoss() \n",
    "    optimizer_housing = optim.Adam(modelo_housing_pytorch.parameters(), lr=0.001, weight_decay=0.0001) \n",
    "    scheduler_housing = optim.lr_scheduler.ReduceLROnPlateau(optimizer_housing, 'min', patience=10, factor=0.5, verbose=True, min_lr=1e-6)\n",
    "else:\n",
    "    print(\"Modelo de regresión no definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc918bc",
   "metadata": {},
   "source": [
    "### 3.4. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073acb18",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS_HOUSING = 200 # Reducido para ejecución más rápida\n",
    "PATIENCE_HOUSING = 20 \n",
    "MODEL_SAVE_PATH_HOUSING = 'best_housing_model_pytorch.pth'\n",
    "history_housing_pytorch = None\n",
    "\n",
    "if modelo_housing_pytorch and criterion_housing and optimizer_housing and train_loader_housing and val_loader_housing:\n",
    "    history_housing_pytorch = entrenar_modelo_regresion_pytorch(\n",
    "        modelo_housing_pytorch, train_loader_housing, val_loader_housing,\n",
    "        criterion_housing, optimizer_housing, scheduler_housing,\n",
    "        num_epochs=NUM_EPOCHS_HOUSING,\n",
    "        patience=PATIENCE_HOUSING,\n",
    "        model_save_path=MODEL_SAVE_PATH_HOUSING,\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    print(\"Componentes de entrenamiento de regresión no disponibles. Saltando entrenamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c725813",
   "metadata": {},
   "source": [
    "### 3.5. Visualización del Historial de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72541474",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history_housing_pytorch:\n",
    "    graficar_historial_regresion_pytorch(history_housing_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831240d3",
   "metadata": {},
   "source": [
    "### 3.6. Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933d4fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if modelo_housing_pytorch and history_housing_pytorch and criterion_housing and test_loader_housing:\n",
    "    # y_test_housing_np fue devuelto por la función de carga y ya está en la escala correcta\n",
    "    # (escalado si scale_target=True, no escalado si scale_target=False)\n",
    "    # para comparar con las predicciones del modelo que también estarán en esa escala.\n",
    "    evaluar_modelo_regresion_pytorch(\n",
    "        modelo_housing_pytorch, test_loader_housing, criterion_housing,\n",
    "        X_test_housing_np, y_test_housing_np, \n",
    "        scaler_y=scaler_y_housing, # Pasar el scaler_y para desescalar en la evaluación si se usó\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    print(\"Modelo de regresión no entrenado o componentes no disponibles. Saltando evaluación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7369f5e0",
   "metadata": {},
   "source": [
    "## 4. Conclusiones del Ejercicio (Regresión California Housing con PyTorch)\n",
    "\n",
    "**Resumen de Hallazgos:**\n",
    "* Se cargó y preprocesó el dataset California Housing, escalando las características de entrada (y opcionalmente el objetivo) y convirtiendo los datos a tensores de PyTorch. Se creó un conjunto de validación.\n",
    "* Se definió una red neuronal (`HousingRegressorNet`) usando `torch.nn.Module` para la tarea de regresión.\n",
    "* El modelo fue compilado con `MSELoss` y el optimizador `Adam` (con `weight_decay` para regularización L2).\n",
    "* Se implementó un bucle de entrenamiento explícito con validación, `ReduceLROnPlateau`, `EarlyStopping` y `ModelCheckpointing`.\n",
    "* El modelo alcanzó un Error Absoluto Medio (MAE) en el conjunto de prueba de **[Completar con MAE obtenido]** y un R² de **[Completar con R² obtenido]**. (El MAE debe interpretarse en la escala original del precio si el target fue desescalado).\n",
    "* Las curvas de aprendizaje y los gráficos de residuales ayudaron a evaluar el ajuste del modelo.\n",
    "\n",
    "**Aprendizaje General:**\n",
    "Este ejercicio demostró la aplicación de PyTorch para un problema de regresión con redes neuronales. Se cubrió el preprocesamiento de datos para PyTorch, la definición de un modelo personalizado, la escritura de un bucle de entrenamiento detallado con control sobre optimizadores y schedulers, y la evaluación del modelo con métricas y visualizaciones relevantes. La flexibilidad de PyTorch permite un control granular sobre todo el proceso de modelado.\n",
    "\n",
    "*(Nota: Los resultados específicos deben completarse después de ejecutar completamente el notebook.)*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
