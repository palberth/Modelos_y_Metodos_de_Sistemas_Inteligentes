{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf41b805",
   "metadata": {},
   "source": [
    "# Clasificación de Especies de Iris con Redes Neuronales (PyTorch) y Regularización\n",
    "\n",
    "**Disciplina:** Aprendizaje Profundo, Redes Neuronales, Clasificación, PyTorch\n",
    "\n",
    "**Objetivo:**\n",
    "El objetivo de este notebook es construir, entrenar y evaluar una red neuronal para clasificar las especies de flores del dataset Iris utilizando PyTorch. Se incorporarán técnicas de preprocesamiento, regularización (Weight Decay y Dropout) y manejo explícito del bucle de entrenamiento con funcionalidades equivalentes a callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau) para mejorar el entrenamiento y la robustez del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e6cdca",
   "metadata": {},
   "source": [
    "## 1. Carga de Librerías y Configuración Inicial\n",
    "\n",
    "**Propósito de esta sección:**\n",
    "Importar todas las bibliotecas necesarias y configurar el entorno para el análisis, incluyendo la fijación de semillas para reproducibilidad y la configuración del dispositivo (CPU/GPU).\n",
    "\n",
    "**Bibliotecas Clave:**\n",
    "* **`numpy`, `pandas`**: Para manipulación de datos.\n",
    "* **`matplotlib.pyplot`, `seaborn`**: Para visualizaciones.\n",
    "* **`sklearn.datasets`**: Para cargar el dataset Iris.\n",
    "* **`sklearn.model_selection`**: Para `train_test_split`.\n",
    "* **`sklearn.preprocessing`**: Para `StandardScaler`.\n",
    "* **`sklearn.metrics`**: Para `classification_report` y `confusion_matrix`.\n",
    "* **`torch`, `torch.nn`, `torch.optim`, `torch.utils.data`**: Para construir y entrenar la red neuronal con PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8a060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comandos mágicos de IPython (opcional en scripts)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068fad6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importación de bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy # Para model checkpointing\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Importar PyTorch\n",
    "PYTORCH_IMPORTED_SUCCESSFULLY = False # <--- DEFINIR LA BANDERA AQUÍ\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import TensorDataset, DataLoader\n",
    "    print(f\"Biblioteca 'torch' importada correctamente. Versión: {torch.__version__}\")\n",
    "    PYTORCH_IMPORTED_SUCCESSFULLY = True # <--- ACTUALIZAR LA BANDERA\n",
    "except ImportError as e:\n",
    "    print(f\"Error al importar 'torch': {e}\")\n",
    "    print(\"Por favor, instálala con 'pip install torch torchvision torchaudio' (o según tu sistema).\")\n",
    "    print(\"El script continuará, pero las secciones de PyTorch probablemente fallarán.\")\n",
    "\n",
    "\n",
    "# Configuración para reproducibilidad\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY: # Solo si PyTorch se importó\n",
    "    torch.manual_seed(SEED)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Configuración de dispositivo (GPU si está disponible, sino CPU)\n",
    "device = torch.device(\"cuda\" if PYTORCH_IMPORTED_SUCCESSFULLY and torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Configuración de estilo y visualización\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa16b7",
   "metadata": {},
   "source": [
    "## 2. Funciones Personalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346f16c",
   "metadata": {},
   "source": [
    "### Descripción de la Función: `cargar_y_preparar_datos_iris_pytorch`\n",
    "\n",
    "**Objetivo Principal:**\n",
    "Cargar el dataset Iris, realizar preprocesamiento (escalado), convertir a tensores de PyTorch y crear DataLoaders.\n",
    "\n",
    "**Características:**\n",
    "* **Procesamiento:**\n",
    "    1. Carga el dataset Iris.\n",
    "    2. Separa características (X) y objetivo (y).\n",
    "    3. Escala las características X usando `StandardScaler`.\n",
    "    4. Convierte X e y a tensores de PyTorch. El objetivo `y` se convierte a `torch.long` para `CrossEntropyLoss`.\n",
    "    5. Divide los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "    6. Crea `TensorDataset` y `DataLoader` para cada conjunto.\n",
    "* **Valor de Retorno:**\n",
    "    * `train_loader, val_loader, test_loader`: DataLoaders para PyTorch.\n",
    "    * `scaler`: El objeto `StandardScaler` ajustado.\n",
    "    * `feature_names`, `target_names`: Nombres.\n",
    "    * `X_train_np, X_val_np, X_test_np, y_train_np, y_val_np, y_test_np`: Datos NumPy para referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e65915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_y_preparar_datos_iris_pytorch(batch_size=16, test_size=0.2, val_size=0.1, random_state=SEED):\n",
    "    \"\"\"\n",
    "    Carga, preprocesa el dataset Iris, lo convierte a tensores PyTorch y crea DataLoaders.\n",
    "    \"\"\"\n",
    "    print(\"Cargando y preparando el dataset Iris para PyTorch...\")\n",
    "    iris = load_iris()\n",
    "    X_np = iris.data\n",
    "    y_np = iris.target \n",
    "    feature_names = iris.feature_names\n",
    "    target_names = iris.target_names\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_np = scaler.fit_transform(X_np)\n",
    "\n",
    "    X_temp_np, X_test_np, y_temp_np, y_test_np = train_test_split(\n",
    "        X_scaled_np, y_np, test_size=test_size, random_state=random_state, stratify=y_np\n",
    "    )\n",
    "    \n",
    "    val_proportion_of_temp = val_size / (1 - test_size) if (1-test_size) > 0 else 0\n",
    "    if val_proportion_of_temp == 0 and len(X_temp_np)>0 : # Si no hay val_size o temp es muy chico\n",
    "        X_train_np, X_val_np, y_train_np, y_val_np = X_temp_np, np.array([]), y_temp_np, np.array([])\n",
    "        # Crear X_val_np, y_val_np vacíos pero con la forma correcta para evitar errores posteriores\n",
    "        X_val_np = np.empty((0, X_train_np.shape[1]), dtype=X_train_np.dtype)\n",
    "        y_val_np = np.empty((0,), dtype=y_train_np.dtype)\n",
    "\n",
    "    elif val_proportion_of_temp > 0 :\n",
    "         X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "            X_temp_np, y_temp_np, test_size=val_proportion_of_temp, random_state=random_state, stratify=y_temp_np\n",
    "        )\n",
    "    else: # Caso X_temp_np está vacío\n",
    "        X_train_np, X_val_np, y_train_np, y_val_np = X_temp_np, X_temp_np, y_temp_np, y_temp_np\n",
    "\n",
    "\n",
    "    # Convertir a tensores PyTorch solo si PyTorch se importó\n",
    "    if PYTORCH_IMPORTED_SUCCESSFULLY:\n",
    "        X_train_torch = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "        y_train_torch = torch.tensor(y_train_np, dtype=torch.long)\n",
    "        X_val_torch = torch.tensor(X_val_np, dtype=torch.float32)\n",
    "        y_val_torch = torch.tensor(y_val_np, dtype=torch.long)\n",
    "        X_test_torch = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "        y_test_torch = torch.tensor(y_test_np, dtype=torch.long)\n",
    "\n",
    "        train_dataset = TensorDataset(X_train_torch, y_train_torch)\n",
    "        # Solo crear val_dataset/loader si X_val_torch no está vacío\n",
    "        val_loader = None\n",
    "        if X_val_torch.shape[0] > 0:\n",
    "            val_dataset = TensorDataset(X_val_torch, y_val_torch)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_torch, y_test_torch)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        train_loader, val_loader, test_loader = None, None, None\n",
    "\n",
    "    print(f\"\\nDimensiones NumPy: X_train: {X_train_np.shape}, y_train: {y_train_np.shape}\")\n",
    "    print(f\"Dimensiones NumPy: X_val: {X_val_np.shape}, y_val: {y_val_np.shape}\")\n",
    "    print(f\"Dimensiones NumPy: X_test: {X_test_np.shape}, y_test: {y_test_np.shape}\")\n",
    "    if train_loader:\n",
    "        print(f\"Tamaños DataLoaders: Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset) if val_loader else 0}, Test: {len(test_loader.dataset)}\")\n",
    "    \n",
    "    return (train_loader, val_loader, test_loader, \n",
    "            scaler, feature_names, target_names, \n",
    "            X_train_np, X_val_np, X_test_np, # Devolver también X_train y X_val en NumPy\n",
    "            y_train_np, y_val_np, y_test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3ebb9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Clase: `IrisClassifierNet`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd45f53e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if PYTORCH_IMPORTED_SUCCESSFULLY:\n",
    "    class IrisClassifierNet(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, dropout_rate=0.3):\n",
    "            super(IrisClassifierNet, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, 64)\n",
    "            self.relu1 = nn.ReLU()\n",
    "            self.dropout1 = nn.Dropout(dropout_rate)\n",
    "            \n",
    "            self.fc2 = nn.Linear(64, 32)\n",
    "            self.relu2 = nn.ReLU()\n",
    "            self.dropout2 = nn.Dropout(dropout_rate)\n",
    "            \n",
    "            self.fc3 = nn.Linear(32, output_dim)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = self.dropout1(x)\n",
    "            \n",
    "            x = self.fc2(x)\n",
    "            x = self.relu2(x)\n",
    "            x = self.dropout2(x)\n",
    "            \n",
    "            x = self.fc3(x) \n",
    "            return x\n",
    "else:\n",
    "    IrisClassifierNet = None # Definir como None si PyTorch no está\n",
    "    print(\"PyTorch no importado, IrisClassifierNet no definido.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c386684b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `entrenar_modelo_pytorch`\n",
    "(Sin cambios, pero su ejecución dependerá de PYTORCH_IMPORTED_SUCCESSFULLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ba24b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def entrenar_modelo_pytorch(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                            num_epochs, patience, model_save_path, device):\n",
    "    if not PYTORCH_IMPORTED_SUCCESSFULLY or model is None:\n",
    "        print(\"PyTorch no disponible o modelo no definido. Saltando entrenamiento.\")\n",
    "        return {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []} # Devolver historial vacío\n",
    "\n",
    "    print(f\"\\nIniciando entrenamiento en {device} por {num_epochs} épocas...\")\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss_train = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss_train += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "        epoch_loss_train = running_loss_train / total_train if total_train > 0 else 0\n",
    "        epoch_acc_train = correct_train / total_train if total_train > 0 else 0\n",
    "        train_losses.append(epoch_loss_train)\n",
    "        train_accuracies.append(epoch_acc_train)\n",
    "\n",
    "        # Fase de Validación (solo si val_loader existe y tiene datos)\n",
    "        epoch_loss_val = float('nan') # Valor por defecto si no hay validación\n",
    "        epoch_acc_val = float('nan')\n",
    "        \n",
    "        if val_loader and len(val_loader.dataset) > 0:\n",
    "            model.eval()\n",
    "            running_loss_val = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss_val_batch = criterion(outputs, labels)\n",
    "                    \n",
    "                    running_loss_val += loss_val_batch.item() * inputs.size(0)\n",
    "                    _, predicted_val = torch.max(outputs.data, 1)\n",
    "                    total_val += labels.size(0)\n",
    "                    correct_val += (predicted_val == labels).sum().item()\n",
    "            \n",
    "            epoch_loss_val = running_loss_val / total_val if total_val > 0 else 0\n",
    "            epoch_acc_val = correct_val / total_val if total_val > 0 else 0\n",
    "        \n",
    "        val_losses.append(epoch_loss_val)\n",
    "        val_accuracies.append(epoch_acc_val)\n",
    "        \n",
    "        print(f\"Época {epoch+1}/{num_epochs} | \"\n",
    "              f\"Pérdida Ent.: {epoch_loss_train:.4f} | Acc Ent.: {epoch_acc_train:.4f} | \"\n",
    "              f\"Pérdida Val.: {epoch_loss_val:.4f} | Acc Val.: {epoch_acc_val:.4f}\")\n",
    "\n",
    "        if scheduler and not np.isnan(epoch_loss_val): # Solo hacer step si hay val_loss\n",
    "            scheduler.step(epoch_loss_val)\n",
    "\n",
    "        if not np.isnan(epoch_loss_val) and epoch_loss_val < best_val_loss:\n",
    "            best_val_loss = epoch_loss_val\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model_state, model_save_path)\n",
    "            print(f\"  Mejora en validación (Pérdida Val.: {best_val_loss:.4f}). Guardando modelo en {model_save_path}\")\n",
    "            epochs_no_improve = 0\n",
    "        elif not np.isnan(epoch_loss_val): # Si hay val_loss pero no mejoró\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"  Sin mejora en validación por {epochs_no_improve} épocas.\")\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping activado en la época {epoch+1}. Mejor val_loss: {best_val_loss:.4f}\")\n",
    "                break\n",
    "        elif np.isnan(epoch_loss_val) and epoch == 0: # Si no hay val_loader, guardamos el primer modelo\n",
    "             best_model_state = copy.deepcopy(model.state_dict())\n",
    "             torch.save(best_model_state, model_save_path)\n",
    "             print(f\"  No hay set de validación. Guardando modelo de época 1 en {model_save_path}\")\n",
    "\n",
    "\n",
    "    if best_model_state:\n",
    "        print(f\"Cargando los pesos del mejor modelo desde {model_save_path} (mejor val_loss: {best_val_loss:.4f})\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "        \n",
    "    return {\"train_loss\": train_losses, \"val_loss\": val_losses, \n",
    "            \"train_acc\": train_accuracies, \"val_acc\": val_accuracies}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4363284",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `graficar_historial_pytorch`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20410494",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def graficar_historial_pytorch(history_dict):\n",
    "    print(\"\\nGraficando historial de entrenamiento (PyTorch)...\")\n",
    "    train_acc = history_dict.get('train_acc')\n",
    "    val_acc = history_dict.get('val_acc')\n",
    "    train_loss = history_dict.get('train_loss')\n",
    "    val_loss = history_dict.get('val_loss')\n",
    "    \n",
    "    # Filtrar NaNs de las listas de validación si no hubo val_loader\n",
    "    val_acc_plot = [v for v in val_acc if not np.isnan(v)] if val_acc else []\n",
    "    val_loss_plot = [v for v in val_loss if not np.isnan(v)] if val_loss else []\n",
    "    \n",
    "    # Ajustar epochs_range para que coincida con la longitud de los datos de entrenamiento,\n",
    "    # y las validaciones solo se plotearán hasta donde tengan datos.\n",
    "    epochs_range_train = range(len(train_loss if train_loss else train_acc))\n",
    "    epochs_range_val = range(len(val_loss_plot if val_loss_plot else val_acc_plot))\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    if train_acc: # Siempre graficar entrenamiento\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs_range_train, train_acc, label='Precisión (Entrenamiento)')\n",
    "        if val_acc_plot: # Solo graficar validación si hay datos\n",
    "            plt.plot(epochs_range_val, val_acc_plot, label='Precisión (Validación)')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Precisión de Entrenamiento y Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('Precisión')\n",
    "\n",
    "    if train_loss: # Siempre graficar entrenamiento\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs_range_train, train_loss, label='Pérdida (Entrenamiento)')\n",
    "        if val_loss_plot: # Solo graficar validación si hay datos\n",
    "            plt.plot(epochs_range_val, val_loss_plot, label='Pérdida (Validación)')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Pérdida de Entrenamiento y Validación')\n",
    "        plt.xlabel('Épocas'); plt.ylabel('Pérdida')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d854eb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Descripción de la Función: `evaluar_modelo_clasificacion_pytorch`\n",
    "(Sin cambios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo_clasificacion_pytorch(model, test_loader, criterion, target_names, device, X_test_numpy_orig, y_test_numpy_orig):\n",
    "    if not PYTORCH_IMPORTED_SUCCESSFULLY or model is None:\n",
    "        print(\"PyTorch no disponible o modelo no definido. Saltando evaluación.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nEvaluando el modelo PyTorch en el conjunto de prueba...\")\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    all_preds_np = []\n",
    "    all_labels_np = [] # No usado para métricas finales si se usa y_test_numpy_orig\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds_np.extend(predicted.cpu().numpy())\n",
    "            # all_labels_np.extend(labels.cpu().numpy()) # No es necesario si usamos y_test_numpy_orig\n",
    "            \n",
    "    avg_test_loss = test_loss / len(y_test_numpy_orig) if len(y_test_numpy_orig) > 0 else 0\n",
    "    # Usar y_test_numpy_orig que es la lista completa de etiquetas verdaderas del test set\n",
    "    final_preds_np = np.array(all_preds_np)\n",
    "    test_accuracy_sklearn = accuracy_score(y_test_numpy_orig, final_preds_np)\n",
    "\n",
    "    print(f\"Pérdida Promedio en el conjunto de prueba: {avg_test_loss:.4f}\")\n",
    "    print(f\"Precisión (sklearn) en el conjunto de prueba: {test_accuracy_sklearn:.4f}\")\n",
    "\n",
    "    print(\"\\nReporte de Clasificación (PyTorch):\")\n",
    "    print(classification_report(y_test_numpy_orig, final_preds_np, target_names=target_names, zero_division=0))\n",
    "\n",
    "    cm = confusion_matrix(y_test_numpy_orig, final_preds_np)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "    plt.title('Matriz de Confusión (PyTorch)')\n",
    "    plt.xlabel('Predicción'); plt.ylabel('Real')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e77044",
   "metadata": {},
   "source": [
    "## 3. Desarrollo del Ejercicio: Clasificación de Iris con PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d3419",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.1. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_IRIS = 8\n",
    "# Ajustar val_size a 0.2 para que sea una proporción del 80% restante si test_size=0.2\n",
    "# val_size_proportion = 0.2 / 0.8 = 0.25\n",
    "(train_loader_iris, val_loader_iris, test_loader_iris, \n",
    " scaler_iris, iris_feature_names, iris_target_names,\n",
    " X_train_iris_np, X_val_iris_np, X_test_iris_np,\n",
    " y_train_iris_np, y_val_iris_np, y_test_iris_np) = cargar_y_preparar_datos_iris_pytorch(\n",
    "                                                        batch_size=BATCH_SIZE_IRIS, \n",
    "                                                        test_size=0.2, \n",
    "                                                        val_size=0.15 # ej: 15% del original para validación\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fbbaf5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.2. Creación del Modelo de Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539254c7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "modelo_iris_pytorch = None # Inicializar\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY and IrisClassifierNet is not None:\n",
    "    # input_dim_iris_actual = X_train_iris_np.shape[1] # Usar el X_train_np devuelto\n",
    "    if X_train_iris_np.shape[0] > 0: # Asegurarse que X_train_np no está vacío\n",
    "         input_dim_iris_actual = X_train_iris_np.shape[1]\n",
    "    elif train_loader_iris and len(train_loader_iris.dataset)>0: #Fallback al loader si X_train_np no se puede usar\n",
    "        sample_inputs, _ = next(iter(train_loader_iris))\n",
    "        input_dim_iris_actual = sample_inputs.shape[1]\n",
    "    else:\n",
    "        print(\"No se pudo determinar input_dim para el modelo Iris. Usando valor por defecto 4.\")\n",
    "        input_dim_iris_actual = 4 # Valor por defecto para Iris\n",
    "        \n",
    "    output_dim_iris = len(iris_target_names) \n",
    "\n",
    "    modelo_iris_pytorch = IrisClassifierNet(input_dim_iris_actual, output_dim_iris, dropout_rate=0.25).to(device)\n",
    "    print(\"\\nResumen del modelo PyTorch (estructura):\")\n",
    "    print(modelo_iris_pytorch)\n",
    "else:\n",
    "    print(\"PyTorch no se importó o IrisClassifierNet no definido, saltando creación de modelo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b380023b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.3. Definición de Pérdida, Optimizador y Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31751631",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_iris, optimizer_iris, scheduler_iris = None, None, None # Inicializar\n",
    "if PYTORCH_IMPORTED_SUCCESSFULLY and modelo_iris_pytorch:\n",
    "    criterion_iris = nn.CrossEntropyLoss()\n",
    "    optimizer_iris = optim.Adam(modelo_iris_pytorch.parameters(), lr=0.001, weight_decay=0.0005) \n",
    "    scheduler_iris = optim.lr_scheduler.ReduceLROnPlateau(optimizer_iris, 'min', patience=7, factor=0.2, verbose=True, min_lr=1e-6)\n",
    "else:\n",
    "    print(\"Modelo no definido, no se pueden crear criterio/optimizador.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bbaee0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.4. Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d5e89",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS_IRIS = 150 # Reducido de 200 para ejecución más rápida\n",
    "PATIENCE_IRIS = 15\n",
    "MODEL_SAVE_PATH_IRIS = 'best_iris_model_pytorch.pth'\n",
    "history_iris_pytorch = None\n",
    "\n",
    "if modelo_iris_pytorch and criterion_iris and optimizer_iris and train_loader_iris and val_loader_iris:\n",
    "    history_iris_pytorch = entrenar_modelo_pytorch(\n",
    "        modelo_iris_pytorch, train_loader_iris, val_loader_iris,\n",
    "        criterion_iris, optimizer_iris, scheduler_iris,\n",
    "        num_epochs=NUM_EPOCHS_IRIS,\n",
    "        patience=PATIENCE_IRIS,\n",
    "        model_save_path=MODEL_SAVE_PATH_IRIS,\n",
    "        device=device\n",
    "    )\n",
    "else:\n",
    "    print(\"Componentes de entrenamiento no disponibles. Saltando entrenamiento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1052dfb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.5. Visualización del Historial de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if history_iris_pytorch:\n",
    "    graficar_historial_pytorch(history_iris_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567751b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3.6. Evaluación del Modelo\n",
    "El mejor modelo ya fue cargado al final de la función `entrenar_modelo_pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e8ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if modelo_iris_pytorch and history_iris_pytorch and criterion_iris and test_loader_iris:\n",
    "    evaluar_modelo_clasificacion_pytorch(\n",
    "        modelo_iris_pytorch, test_loader_iris, criterion_iris, \n",
    "        iris_target_names, device,\n",
    "        X_test_iris_np, y_test_iris_np \n",
    "    )\n",
    "else:\n",
    "    print(\"Modelo no entrenado o componentes no disponibles. Saltando evaluación.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de10e708",
   "metadata": {},
   "source": [
    "## 4. Conclusiones del Ejercicio (Clasificación Iris con PyTorch)\n",
    "\n",
    "**Resumen de Hallazgos:**\n",
    "* Se cargó y preprocesó el dataset Iris, escalando características y convirtiendo los datos a tensores de PyTorch para su uso con DataLoaders. Se creó un conjunto de validación.\n",
    "* Se definió una red neuronal (`IrisClassifierNet`) usando `torch.nn.Module`, con capas lineales, activaciones ReLU y Dropout.\n",
    "* El modelo fue compilado con `CrossEntropyLoss` y el optimizador `Adam` (con `weight_decay` para regularización L2).\n",
    "* Se implementó un bucle de entrenamiento explícito, incorporando:\n",
    "    * Validación en cada época.\n",
    "    * `ReduceLROnPlateau` para ajustar dinámicamente la tasa de aprendizaje.\n",
    "    * Lógica manual para `EarlyStopping` y `ModelCheckpointing`.\n",
    "* La precisión final alcanzada en el conjunto de prueba fue de **[Completar con la precisión obtenida]**.\n",
    "* El reporte de clasificación y la matriz de confusión mostraron el rendimiento del modelo en cada clase.\n",
    "* Las curvas de aprendizaje indicaron **[Describir si hubo sobreajuste, si EarlyStopping actuó, etc.]**.\n",
    "\n",
    "**Aprendizaje General:**\n",
    "Este ejercicio demostró cómo construir, entrenar y evaluar una red neuronal para clasificación multiclase utilizando PyTorch. Se destacó la flexibilidad y el control que ofrece PyTorch al requerir la escritura explícita del bucle de entrenamiento y la gestión de callbacks. Se aplicaron técnicas de regularización como Dropout y decaimiento de pesos (L2) para mejorar la generalización del modelo.\n",
    "\n",
    "*(Nota: Los resultados específicos deben completarse después de ejecutar completamente el notebook.)*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
